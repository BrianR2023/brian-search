<!DOCTYPE html>
<html>
<head>
  <title>Brazo Robótico Controlado por Voz</title>
  <style>
    body {
      background-color: black;
      color: white;
      text-align: center;
      font-family: 'Lucida Console', sans-serif;
    }

    h1 {
      margin-top: 40px;
    }

    button {
      margin-top: 20px;
    }

    p {
      font-size: 18px;
      margin-top: 10px;
    }

    #sound-levels {
      width: 200px;
      height: 30px;
      background-color: #444;
      position: relative;
      margin: 20px auto;
    }

    #sound-level-bar {
      height: 100%;
      width: 0;
      background-color: #f00;
      transition: width 0.1s;
    }
  </style>
</head>
<body>
  <h1>Control de Brazo Robótico por Voz</h1>
  <button id="start-btn">Iniciar Reconocimiento de Voz</button>
  <button id="stop-btn">Detener Reconocimiento de Voz</button>
  <p>Proyecto de Brian Rodríguez, Kevin Rodríguez, Rafa y Antony</p>
  <div id="sound-levels">
    <div id="sound-level-bar"></div>
  </div>

  <script>
    const apiKey = 'TU_CLAVE_DE_API'; // Reemplaza con tu clave de API de Google Cloud

    // Configurar la API de reconocimiento de voz del navegador
    const recognition = new webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'es-ES'; // Puedes ajustar el idioma según tus necesidades
    let recognitionStarted = false;

    // Obtener los botones por su ID
    const startButton = document.getElementById('start-btn');
    const stopButton = document.getElementById('stop-btn');

    startButton.addEventListener('click', () => {
      // Solicitar permiso para acceder al micrófono solo si el reconocimiento no ha comenzado
      if (!recognitionStarted) {
        navigator.mediaDevices.getUserMedia({ audio: true })
          .then((stream) => {
            // Visualizar los niveles de sonido en tiempo real
            visualizeSoundLevels(stream);

            recognition.start();
            recognitionStarted = true;
            console.log('Reconocimiento de voz iniciado.');
          })
          .catch((error) => {
            console.error('Permiso denegado o error al acceder al micrófono:', error);
          });
      }
    });

    stopButton.addEventListener('click', () => {
      // Detener el reconocimiento solo si se ha iniciado previamente
      if (recognitionStarted) {
        recognition.stop();
        recognitionStarted = false;
        console.log('Reconocimiento de voz detenido.');
      }
    });

    // Función para interpretar los comandos de voz y controlar el brazo robótico
    function interpretarComando(comando) {
      // Convertir el comando a minúsculas para hacer coincidencias sin distinción de mayúsculas/minúsculas
      const comandoMin = comando.toLowerCase();

      if (comandoMin.includes('arriba')) {
        console.log('Mover el brazo hacia arriba.');
        // Aquí debes agregar la lógica para mover el brazo hacia arriba
      } else if (comandoMin.includes('abajo')) {
        console.log('Mover el brazo hacia abajo.');
        // Aquí debes agregar la lógica para mover el brazo hacia abajo
      } else if (comandoMin.includes('abrir')) {
        console.log('Abrir el brazo.');
        // Aquí debes agregar la lógica para abrir el brazo
      } else if (comandoMin.includes('cerrar')) {
        console.log('Cerrar el brazo.');
        // Aquí debes agregar la lógica para cerrar el brazo
      } else {
        console.log('Comando no reconocido.');
      }
    }

    recognition.onresult = (event) => {
      const transcript = event.results[event.results.length - 1][0].transcript.trim();
      console.log('Comando detectado:', transcript);

      interpretarComando(transcript); // Llamamos a la función para interpretar el comando
    };

    // Función para visualizar los niveles de sonido en tiempo real
    function visualizeSoundLevels(stream) {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);

      analyser.fftSize = 256;
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      const soundLevelBar = document.getElementById('sound-level-bar');
      const soundLevelsDiv = document.getElementById('sound-levels');
      const soundLevelsWidth = soundLevelsDiv.offsetWidth;

      function draw() {
        analyser.getByteFrequencyData(dataArray);

        let sum = 0;
        dataArray.forEach(value => sum += value);
        const average = sum / bufferLength;
        const percentage = average / 256;

        const barWidth = soundLevelsWidth * percentage;
        soundLevelBar.style.width = `${barWidth}px`;

        requestAnimationFrame(draw);
      }

      draw();
    }

  </script>
</body>
</html>
